
- Garante que a thread principal s√≥ continue ap√≥s a thread especificada terminar.
# ‚öôÔ∏è Gest√£o de Tarefas

Sistemas de computa√ß√£o geralmente t√™m mais tarefas a executar do que processadores dispon√≠veis. Por isso, √© necess√°rio **multiplexar o processador**, ou seja, **compartilh√°-lo entre as tarefas**.

## üéØ Objetivos da Gest√£o de Tasks

- Executar v√°rias tarefas **simultaneamente**, mesmo com processador(es) limitado(s).
- Atribuir **tempo de CPU** a cada tarefa conforme suas **necessidades**.

    - Solu√ß√£o ing√™nua :Um processador por tarefa ‚Üí **Invi√°vel** t√©cnica e economicamente.

    - Solu√ß√£o pr√°tica: **Compartilhamento inteligente do processador** entre tarefas (multiplexa√ß√£o).

## üîÑ Conceito de Programa

**Programa** √© um conjunto de uma ou mais sequ√™ncias de instru√ß√µes escritas para resolver
um problema espec√≠fico, constituindo assim uma aplica√ß√£o ou utilit√°rio.

Representa um **conceito est√°tico**, sem:
  - **Estado interno**
  - **Intera√ß√µes**

## üîÑ Conceito de Task

 **Tarefa**  √© uma **execu√ß√£o de um fluxo sequencial de instru√ß√µes** por um processador.

Representa uma **atividade din√¢mica**, com:
  - **Estado interno** que muda com o tempo
  - **Intera√ß√µes** com o usu√°rio, dispositivos ou outras tasks
- Pode ser implementada como **processo** ou **thread**.

### üìù Diferen√ßa entre Programa e Task

#### A tarefa √© o programa sendo executado 

| Conceito | Programa | Task |
|----------|----------|--------|
| Natureza | Est√°tico | Din√¢mico |
| Defini√ß√£o | Conjunto de instru√ß√µes (c√≥digo) | Execu√ß√£o das instru√ß√µes por um processador |
| Estado interno | N√£o possui | Possui (evolui com a execu√ß√£o) |
| Intera√ß√µes | Nenhuma | Com usu√°rio, SO e outras tarefas |
| Exemplo | `/usr/bin/vi` ou `notepad.exe` | Vim aberto editando um arquivo |



## Sistemas Multitarefas

Os **sistemas multitarefas** surgiram como evolu√ß√£o dos sistemas com monitor para melhorar o aproveitamento do processador, que ficava ocioso durante opera√ß√µes lentas de entrada/sa√≠da (E/S), como leitura de discos ou fitas magn√©ticas.

### üõ† Problema
- O processador era muito mais r√°pido que os dispositivos de E/S.
- Enquanto uma tarefa aguardava dados externos, o processador ficava ocioso.
- Isso causava desperd√≠cio de recursos e energia.

### ‚úÖ Solu√ß√£o
- Permitir que o **monitor suspenda** tarefas que est√£o esperando dados.
- Enquanto isso, o processador executa **outra tarefa**.
- Quando os dados estiverem prontos, a tarefa anterior √© **retomada de onde parou**.

### üîÑ Funcionamento
1. Uma tarefa ativa solicita leitura de dados ‚Üí √© **suspensa**.
2. O monitor inicia a execu√ß√£o de outra tarefa.
3. Quando os dados da primeira tarefa chegam, ela √© **retomada**.
4. Ap√≥s a execu√ß√£o, a tarefa **termina** e libera recursos.

![multi](multitarefa.png)


### üîÅ Estados de uma tarefa
- **Ativa**: est√° sendo executada.
- **Pronta**: est√° esperando pelo processador.
- **Suspensa**: est√° aguardando entrada/sa√≠da ou evento externo.

![dmulti](dmulti.png)


## Sistemas de Tempo Compartilhado

Os **sistemas de tempo compartilhado** (*time-sharing*) surgiram como uma evolu√ß√£o dos sistemas multitarefas para resolver problemas de monopoliza√ß√£o do processador e permitir aplica√ß√µes interativas.

![tempo](tempo.png)
  Implementa√ß√£o do tempo compartilhado

### üõ† Problema
- Tarefas sem opera√ß√µes de E/S podiam executar indefinidamente, **monopolizando o processador**
- Em sistemas interativos (como editores de texto ou terminais), os usu√°rios precisavam de **resposta r√°pida**
- O sistema multitarefa comum s√≥ trocava de tarefa quando havia E/S, o que n√£o era suficiente para garantir **justi√ßa** ou **responsividade**

### ‚úÖ Solu√ß√£o
- Introduzir o conceito de **fatia de tempo** (*quantum*) para cada tarefa
- Implementar **preemp√ß√£o por tempo**: interromper a tarefa em execu√ß√£o quando seu tempo acabar, mesmo que ela n√£o solicite E/S

  >Preemp√ß√£o √© o ato de interromper uma tarefa em execu√ß√£o para transferir o controle do processador para outra tarefa.

- Criar um **escalonador** que gerencia a fila de tarefas prontas de forma circular

#### üîÑ Funcionamento
1. Cada tarefa recebe o processador por um **quantum** fixo (ex: 10‚Äì200 ms)
2. Um **temporizador de hardware** (*timer*) gera interrup√ß√µes peri√≥dicas (*ticks*)
3. A cada *tick*, o contador do quantum da tarefa √© decrementado
4. Quando o quantum chega a **zero**, a tarefa √© **interrompida** e volta para o final da fila de prontas
5. Outra tarefa da fila recebe o processador

### üîÅ Estados de uma Tarefa (com Preemp√ß√£o)

| Estado | Descri√ß√£o |
|--------|-----------|
| **Nova** | Tarefa sendo criada/carregada na mem√≥ria |
| **Pronta** | Na mem√≥ria, aguardando na fila pelo processador |
| **Executando** | Usando o processador no momento |
| **Suspensa** | Aguardando E/S, evento ou sincroniza√ß√£o |
| **Terminada** | Finalizada, aguardando limpeza de recursos |


![tempo](dtempo.png)
### ‚ûï Transi√ß√£o Adicional
- **Executando ‚Üí Pronta**: ocorre por **preemp√ß√£o por tempo** (fim do quantum), al√©m das transi√ß√µes por E/S do modelo multitarefa tradicional



---


## **Contextos**
- Cada tarefa possui um **contexto**, que inclui o estado do processador (registradores, PC, SP) e recursos utilizados (arquivos, mem√≥ria, etc.).
- O **TCB** (Task Control Block) √© a estrutura no n√∫cleo que armazena:
  - Identificador, estado, contexto do processador, √°reas de mem√≥ria, recursos abertos, informa√ß√µes de ger√™ncia.

---

### **Trocas de Contexto**
- **Troca de contexto**: opera√ß√£o de suspender uma tarefa e retomar outra, salvando/restaurando seu contexto.
- Envolve:
  - **Despachante** (dispatcher): mecanismo de salvar/restaurar contexto. - baixo n√≠vel
  - **Escalonador** (scheduler): pol√≠tica de escolha da pr√≥xima tarefa.
- Efici√™ncia:  

A efici√™ncia do uso do processador √©:

$$ \mathcal{E} = \frac{t_q}{t_q + t_{tc}} $$

Onde:
- $\mathcal{E}$ = efici√™ncia
- $t_q$ = dura√ß√£o do quantum
- $t_{tc}$ = tempo de troca de contexto

#### Exemplo
![troca](troca.png)

**Resumo da Troca de Contexto:**

1. Tarefa A est√° executando.
2. O temporizador de hardware gera uma interrup√ß√£o, transferindo o controle para o n√∫cleo.
3. O despachante √© ativado.
4. O estado da tarefa A √© salvo em seu TCB.
5. O escalonador seleciona a pr√≥xima tarefa (B).
6. O despachante restaura o estado da tarefa B e a coloca em execu√ß√£o.

---

### **Implementar tarefas: Processos**
- **Processo**: cont√™iner de recursos (mem√≥ria, arquivos, conex√µes) que pode conter uma ou mais tarefas.

- Hierarquia: processos formam uma √°rvore (Linux). No Windows, n√£o h√° hierarquia.
- **PCB** (Process Control Block): descritor do processo no n√∫cleo (PID, prioridade, recursos, etc.).

![proc](processo.png)

Cria√ß√£o no UNIX: `fork()` + `execve()`

![criacao](criacao.png)

A chamada `fork()` cria um novo processo (filho) id√™ntico ao processo original (pai), ambos continuando a execu√ß√£o a partir do ponto da chamada com o pai recebendo o PID do filho. O filho, ent√£o, normalmente executa `execve()`, que substitui seu c√≥digo pelo de um novo programa, carregando um execut√°vel informado como par√¢metro.

---

### **Implementar tarefas: Threads**
- **Thread**: fluxo de execu√ß√£o independente dentro de um processo.
- Compartilham mem√≥ria e recursos do processo, mas t√™m contexto pr√≥prio (pilha, registradores).
- Por default, um processo tem uma thread.

- Threads de usu√°rio: gerenciadas pela biblioteca de threads (ex: `pthread`)(dentro de um processo)

- Threads de n√∫cleo: gerenciadas pelo sistema operacional.


  #### Algumas fun√ß√µes da biblioteca `pthread` em C:
  - **pthread_create**

    - Usada para criar uma nova thread.
    - Par√¢metros:
      - Identificador da thread (pthread_t *thread)
      - Atributos da thread (const pthread_attr_t *attr), pode ser NULL
      - Fun√ß√£o que a thread executar√° (void *(*start_routine)(void *))
      - Argumento para a fun√ß√£o (void *arg), pode ser NULL
    - Exemplo de uso:
      ```c
      pthread_t tid;
      pthread_create(&tid, NULL, func, NULL); // cria a thread
      ```


  - **pthread_join**

    - Usada para esperar o t√©rmino de uma thread.
    - Par√¢metros:
      - Identificador da thread (pthread_t thread)
      - Ponteiro para valor de retorno da thread (void **retval), pode ser NULL
    - Exemplo de uso:
      ```c
      pthread_t tid;
      pthread_create(&tid, NULL, func, NULL);
      pthread_join(tid, NULL); // espera a thread terminar
      ```


  
- **Modelos de implementa√ß√£o**:
  - **N:1**: M√∫ltiplas threads de usu√°rio ‚Üí 1 thread de n√∫cleo (leve, mas sem paralelismo real).
    - Python, Ruby
    - Chamados Fibers (co-rotinas) ou Green Threads

  ![threadn1](threadn1.png)

  - **1:1**: Cada thread de usu√°rio ‚Üí 1 thread de n√∫cleo (comum em sistemas modernos, suporta paralelismo).

    - Linux (N√∫cleo 2.6+), Windows, macOS
    - Pouco escal√°vel (overhead de muitas threads de n√∫cleo)

  ![thread11](thread11.png)

  - **N:M**: H√≠brido; balanceia escalabilidade e desempenho.

    - Suporte multithread dentro do kernel mas tamb√©m existe uma biblioteca de threads no espa√ßo do usu√°rio.
    -thread pool varia de acordo com a carga de trabalho.
    - Solaris, FreeBSD


  ![threadnm](threadnm.png)



---

### **Processos vs. Threads**
| Crit√©rio          | Processos                           | Threads                            |
|-------------------|-------------------------------------|------------------------------------|
| Cria√ß√£o           | Lenta                               | R√°pida                             |
| Isolamento        | Alto (seguran√ßa)                    | Baixo (compartilham mem√≥ria)       |
| Comunica√ß√£o       | Complexa (IPC)                      | Simples (mem√≥ria compartilhada)    |
| Robustez          | Alta (erro n√£o propaga)             | Baixa (erro afeta todo o processo) |
| Exemplos          | Apache 1.*, PostgreSQL              | IIS, LibreOffice                  |
| Modelo H√≠brido    | Chrome, Firefox, Apache 2.*         | Combina vantagens de ambos         |


  

---
### Lei de Amdahl

A **Lei de Amdahl** √© um princ√≠pio da computa√ß√£o que calcula o m√°ximo ganho de desempenho (ou **Speedup**) que se pode obter ao otimizar um sistema. Sua principal conclus√£o √© que esse ganho √© sempre limitado pela parte do sistema que n√£o foi melhorada.

#### Termos T√©cnicos Principais

* **Parte Sequencial (`1 - f`):** √â a fra√ß√£o de um programa que deve ser executada em ordem, passo a passo, e n√£o pode ser dividida entre m√∫ltiplos processadores. Ela funciona como uma "√¢ncora" ou um **gargalo (bottleneck)**, determinando o limite m√°ximo de acelera√ß√£o.

* **Parte Paraleliz√°vel (`f`):** √â a fra√ß√£o do programa que pode ser dividida em tarefas menores e executada simultaneamente por v√°rios processadores para economizar tempo.

* **N (N√∫mero de Processadores):** Refere-se √† quantidade de unidades de processamento dispon√≠veis para executar a parte paraleliz√°vel da tarefa.

* **Speedup (Acelera√ß√£o):** √â o fator que mede "quantas vezes mais r√°pido" um programa se torna ap√≥s uma melhoria. √â calculado pela f√≥rmula `Speedup = 1 / ((1 - f) + f / N)`. Conforme `N` aumenta, o `Speedup` se aproxima do seu limite m√°ximo de `1 / (1 - f)`.

Em resumo, a Lei de Amdahl nos ensina que adicionar mais processadores a um sistema tem um **retorno decrescente**: os ganhos de velocidade s√£o grandes no in√≠cio, mas se tornam cada vez menores √† medida que a parte sequencial do trabalho se torna o fator dominante.